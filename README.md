# My Data Science Portfolio

Welcome to my Data Science Portfolio repository! This meticulously organized collection serves as a chronicle of my journey in the captivating field of data science. Within these digital walls, you will find a curated showcase of my progression, featuring detailed and well-crafted code implementations, as well as comprehensive analytical reports.

## What to Expect

1. **Structured Codebase:**
   Dive into a neatly organized codebase that reflects both elegance and functionality. 

2. **Insightful Reports:**
   Explore detailed reports that accompany the code. Unpack the story behind the algorithms, understand the nuances, and witness the magic unfold.

## Machine Learnings Algorithms that has been explored

- **Linear Regression:**  Predicts a continuous outcome based on one or more predictor variables. Useful when exploring the relationship between independent and dependent variables, allowing for predictions of quantitative values.
- **Logistic Regression:**  Used for binary classification problems, predicting the probability of an event. Useful in scenarios where the outcome is categorical.
- **Penalizations:** Ridge(L2), LASSO(L1), Elastic Net; These penalization techniques are crucial for regularizing models and preventing overfitting, particularly when dealing with high-dimensional datasets or datasets with correlated features.
- **Principal Component Analysis (PCA):**  Reduces dimensionality while preserving data variance. Useful for feature extraction and visualization, aiding in the compression of large datasets and noise reduction.
- **Hierarchical Clustering:**  A clustering algorithm that organizes data points into a hierarchical tree-like structure, revealing relationships and similarities among data. Useful in exploratory data analysis and understanding hierarchical structures in datasets.
- **[K-Means Clustering](https://github.com/GergelyMarias/MyDataSciencePortfolio/blob/main/KMeansClustering.pdf):**  Groups data into k clusters based on similarity. Useful for partitioning data into distinct groups.
- **K-Nearest Neighbors (KNN):**  Classifies data points based on the majority class among their k-nearest neighbors. Valuable for pattern recognition.
- **Naive Bayes:**  A probabilistic algorithm based on Bayes' theorem, often used for text classification. Efficient and useful in scenarios where independence assumptions are reasonable.
- **Decision Trees:**  Tree-like models that make decisions based on input features. Useful for both classification and regression tasks, decision trees are interpretable and offer insights into feature importance.
- **Conditional Inference Tree:**  A decision tree algorithm that employs conditional inference tests at each split, making it robust and statistically sound for various types of data. Particularly useful when maintaining statistical rigor is crucial and interpretability is vital.
- **[Random Forest](https://github.com/GergelyMarias/MyDataSciencePortfolio/blob/main/RandomForest.pdf):**  An ensemble of decision trees for improved accuracy and robustness. Useful when seeking higher predictive performance by aggregating multiple decision trees, reducing overfitting and enhancing generalization across diverse datasets.
- **[Gradient Boosting Machines](https://github.com/GergelyMarias/MyDataSciencePortfolio/blob/main/XGBoosting.pdf) (XGBoost):**  An ensemble learning method that builds trees sequentially, correcting errors of previous ones. Powerful for improving predictive accuracy, XGBoost is commonly used in competitions and real-world applications where performance is critical, such as credit scoring or predictive maintenance.
- **Support Vector Machines (SVM):**  Used for classification and regression analysis, separating data into distinct classes. Particularly effective for their ability to handle complex relationships.
- **Neural Networks:**  Deep learning models composed of interconnected layers of nodes, used for various tasks like image recognition and natural language processing.
- **Recurrent Neural Networks (RNN):**  Neural networks designed for sequence data, such as time series or text. Valuable in applications requiring memory of past events.
- **Long Short-Term Memory (LSTM):**  A type of RNN designed to overcome the vanishing gradient problem. Essential for capturing long-term dependencies in sequential data.
- **Convolutional Neural Networks (CNN):**  Deep learning models specifically designed for image recognition. Effective in capturing spatial hierarchies and patterns in images.

## Connect with Me:
[LinkedIn](https://www.linkedin.com/in/mariasgergely/)

Thank you for visiting my Data Science Portfolio! ðŸš€
